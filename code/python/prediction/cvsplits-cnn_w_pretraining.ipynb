{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Statistical Model\n",
    "We recommend using linux for running the statistical model notebooks. The RAM requirements are ~24GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.12.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from scipy.stats import rv_discrete, wasserstein_distance\n",
    "from KDEpy import FFTKDE\n",
    "import cv2\n",
    "from cv2 import EMD, DIST_L2\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils_data\n",
    "import torch.distributions as dist\n",
    "import pickle\n",
    "import kde_emd_proc as kep\n",
    "from importlib import reload\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "\n",
    "import visual\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "print(\"Using Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_green = (17/255, 119/255, 51/255)\n",
    "rgb_skyblue = (136/255, 204/255, 238/255)\n",
    "rgb_magenta = (170/255, 68/255, 153/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 32\n",
    "resize_shape = (100,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ball_pos(world, hole):\n",
    "    hole_pos = world[\"hole_positions\"][hole]\n",
    "    return {\"x\": hole_pos, \"y\": world[\"height\"]-world[\"ball_radius\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(world, hole, cutoff=None, resize_shape=None):\n",
    "    ball_pos = get_ball_pos(world, hole)\n",
    "    img = visual.snapshot(\n",
    "        world,\n",
    "        ret_np=True,\n",
    "        ball_pos=ball_pos,\n",
    "        unity_coordinates=True\n",
    "    )\n",
    "    if cutoff:\n",
    "        img = img[:-cutoff,cutoff:-cutoff]\n",
    "    if resize_shape:\n",
    "        img = cv2.resize(\n",
    "            img, dsize=resize_shape, interpolation=cv2.INTER_CUBIC\n",
    "        )\n",
    "    norm = 255./2\n",
    "    return (img.mean(-1)[None] - norm)/norm # move channels to first dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(samp, cutoff=None, resize_shape=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        samp: dict\n",
    "            \"world\": dict\n",
    "                a world state\n",
    "            \"final_positions\": list\n",
    "                the drop locations for the ball from each hole\n",
    "        resize_shape: None or tuple\n",
    "            if tuple is argued, will resize_shape image to this\n",
    "            height and width\n",
    "    Returns:\n",
    "        imgs: list of ndarrays (1,H,W)\n",
    "        labels: list of floats\n",
    "            the drop locations\n",
    "    \"\"\"\n",
    "    world, final_positions = samp[\"world\"], samp[\"final_positions\"]\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    n_holes = len(final_positions)\n",
    "    for hole in range(n_holes):\n",
    "        img = get_img(world, hole, cutoff=cutoff, resize_shape=resize_shape)\n",
    "        imgs.append(img) \n",
    "        labels.append(final_positions[hole])\n",
    "    return imgs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_visual_data(data, beta_scale=False, cutoff=32, resize_shape=(100,120), verbose=True):\n",
    "    \"\"\"\n",
    "    Processes the data made by the file `world_generation_script.py` into\n",
    "    inputs X and labels y.\n",
    "    \n",
    "    Args\n",
    "        data: list of dicts\n",
    "            each dict should have the keys \"world\" and \"final_positions\".\n",
    "            See the input to `process_sample()`\n",
    "        beta_scale: bool\n",
    "            if true, will scale the labels to be on the interval of 0\n",
    "            to 1.\n",
    "        downsize_factor: int\n",
    "            the amount to downsize the images by. greater numbers means\n",
    "            smaller images.\n",
    "        resize_shape: None or tuple\n",
    "            if tuple is argued, will resize images to this\n",
    "            height and width\n",
    "        cutoff: int\n",
    "            a value to cutoff the edges of the image.\n",
    "    Returns:\n",
    "        X: ndarray (B,1,H,W)\n",
    "            the image inputs\n",
    "        y: ndarray (B,)\n",
    "            the corresponding labels\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    iterable = data\n",
    "    if verbose:\n",
    "        iterable = tqdm(data)\n",
    "    for samp in iterable:\n",
    "        imgs, labels = process_sample(samp, cutoff=cutoff, resize_shape=resize_shape)\n",
    "        X.append(imgs)\n",
    "        y.append(labels)\n",
    "    img_shape = imgs[0].shape\n",
    "    X = np.asarray(X, dtype=float).reshape(-1, *img_shape)\n",
    "    y = np.asarray(y, dtype=float).reshape(-1)\n",
    "    if beta_scale:\n",
    "        og_scale = 600 # original width of image\n",
    "        y = y/og_scale # normalizing by width of the image\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data = pd.read_csv(\"../../../data/human_data/prediction/prediction_long.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "human_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_kde_dict = kep.compute_kdes(human_data, \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cv_splits.pkl\", \"rb\") as f:\n",
    "    splits = pickle.load(f)\n",
    "splits[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cv_splits.pkl\", \"rb\") as f:\n",
    "    splits = pickle.load(f)\n",
    "splits[\"train\"]\n",
    "\n",
    "world_key = splits[\"key\"]\n",
    "\n",
    "keys = set(splits.keys())\n",
    "keys.remove(\"key\")\n",
    "print(\"splits:\")\n",
    "for k in keys:\n",
    "    print(k, splits[k].shape)\n",
    "\n",
    "og_shapes = {k: splits[k].shape for k in keys}\n",
    "flat_splits = {k: splits[k].reshape(-1) for k in keys}\n",
    "world_num_splits = {\n",
    "    k: np.asarray([world_key[i][1] for i in flat_splits[k]]) for k in keys\n",
    "}\n",
    "world_num_splits = {k: v.reshape(og_shapes[k]) for k,v in world_num_splits.items()}\n",
    "print(\"\\nworld num splits:\")\n",
    "for k in keys:\n",
    "    print(k, world_num_splits[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_worlds(df, worlds):\n",
    "    \"\"\"\n",
    "    df: human data frame\n",
    "        needs \"world\" column referring to world number (not index)\n",
    "    worlds: set or list of ints \n",
    "        the world numbers (not indices)\n",
    "    \"\"\"\n",
    "    return df.loc[df[\"world\"].isin(worlds)]\n",
    "    \n",
    "def split_df(df, train_worlds, test_worlds):\n",
    "    train_df = isolate_worlds(df, train_worlds)\n",
    "    test_df = isolate_worlds(df, test_worlds)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have a dict that has 100 splits in which the total set of worlds is split into train and test.\n",
    "# We can use these splits in conjunction with the `split_df` function to create dataframes to train on.\n",
    "print(\"First split:\")\n",
    "print(\"Train:\", world_num_splits[\"train\"][0])\n",
    "print(\"Test:\", world_num_splits[\"test\"][0])\n",
    "assert len(set(world_num_splits[\"train\"][0]).intersection(set(world_num_splits[\"test\"][0])))==0\n",
    "train_df, test_df = split_df(\n",
    "    human_data,\n",
    "    train_worlds=world_num_splits[\"train\"][0], \n",
    "    test_worlds=world_num_splits[\"test\"][0], \n",
    ")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_means = human_data.groupby([\"world\", \"hole\"])[\"response\"].agg([\"mean\"]).reset_index()\n",
    "human_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worlds = human_data[\"world\"].unique()\n",
    "worlds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, resizer=None, bnorm=True, lnorm=False, leading_norm=True, noise=0):\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        if leading_norm:\n",
    "            if bnorm:\n",
    "                modules.append(nn.BatchNorm2d(inplanes))\n",
    "            if lnorm:\n",
    "                modules.append(nn.LayerNorm(inplanes))\n",
    "            if noise:\n",
    "                modules.append(GaussianNoise(noise))\n",
    "        modules.append(\n",
    "            nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        )\n",
    "        if bnorm:\n",
    "            modules.append(nn.BatchNorm2d(planes))\n",
    "        if lnorm:\n",
    "            modules.append(nn.LayerNorm(planes))\n",
    "        if noise:\n",
    "            modules.append(GaussianNoise(noise))\n",
    "        modules.append(nn.GELU())\n",
    "        modules.append(\n",
    "            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "        if bnorm:\n",
    "            modules.append(nn.BatchNorm2d(planes))\n",
    "        if lnorm:\n",
    "            modules.append(nn.LayerNorm(planes))\n",
    "        if noise:\n",
    "            modules.append(GaussianNoise(noise))\n",
    "        self.fxns = nn.Sequential(*modules)\n",
    "        self.resizer = resizer\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.fxns(x)\n",
    "\n",
    "        if self.resizer is not None:\n",
    "            identity = self.resizer(x)\n",
    "\n",
    "        out += identity\n",
    "        out = torch.nn.functional.gelu(out)\n",
    "        return out\n",
    "    \n",
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, std=0.05):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"std\", torch.FloatTensor([std]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            gauss = torch.randn_like(x)*self.std\n",
    "            return x + gauss\n",
    "        return x\n",
    "    \n",
    "class res_gmm(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 layer_counts=[2,2,2],\n",
    "                 chans=[12,24,48],\n",
    "                 num_comp=10,\n",
    "                 bnorm=True,\n",
    "                 lnorm=False,\n",
    "                 leading_norm=True,\n",
    "                 noise=0,\n",
    "                 *args, **kwargs):\n",
    "        \"\"\"\n",
    "        layer_counts: list of ints\n",
    "            denotes the number of res blocks for each channel change\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_shape = input_shape[-3:]\n",
    "        self.in_conv = [nn.Conv2d(self.input_shape[0], chans[0], kernel_size=7, stride=2, padding=3,bias=False)]\n",
    "        if bnorm:\n",
    "            self.in_conv.append(nn.BatchNorm2d(chans[0]))\n",
    "        if lnorm:\n",
    "            self.in_conv.append(nn.LayerNorm(chans[0]))\n",
    "        if noise:\n",
    "            self.in_conv.append(GaussianNoise(noise))\n",
    "        self.in_conv.append(nn.GELU())\n",
    "        self.in_conv = nn.Sequential(*self.in_conv)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([])\n",
    "        chans.append(chans[-1])\n",
    "        for i, (chan,n_layers) in enumerate(zip(chans,layer_counts)):\n",
    "            self.blocks.append(\n",
    "                self._make_layer(\n",
    "                    BasicBlock, chan, chans[i+1], n_layers, stride=2 if i!=0 else 1, noise=noise\n",
    "                )\n",
    "            )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.a_out = nn.Linear(    chans[-1], num_comp)\n",
    "        self.mu_out = nn.Linear(   chans[-1], num_comp)\n",
    "        self.sigma_out = nn.Linear(chans[-1], num_comp)\n",
    "            \n",
    "    def _make_layer(self, block, inplanes, planes, n_blocks, stride=1, bnorm=True, lnorm=False, leading_norm=True, noise=0):\n",
    "        resizer = None\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            modules = [nn.Conv2d(inplanes, planes, 1, stride, bias=False)]\n",
    "            if bnorm: modules.append(nn.BatchNorm2d(planes))\n",
    "            if lnorm: modules.append(nn.LayerNorm(planes))\n",
    "            if noise: modules.append(GaussianNoise(noise))\n",
    "            resizer = nn.Sequential(*modules)\n",
    "        layers = []\n",
    "        layers.append(block(\n",
    "            inplanes=inplanes,\n",
    "            planes=planes,\n",
    "            stride=stride,\n",
    "            resizer=resizer,\n",
    "            bnorm=bnorm,\n",
    "            lnorm=lnorm,\n",
    "            leading_norm=leading_norm,\n",
    "            noise=noise,\n",
    "        ))\n",
    "        inplanes = planes\n",
    "        for _ in range(1, n_blocks):\n",
    "            layers.append(block(inplanes, planes, stride=1, bnorm=bnorm, lnorm=lnorm, leading_norm=leading_norm, noise=noise))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def get_vars(self, fx):\n",
    "        a =  self.a_out(fx).softmax(dim=-1)\n",
    "        mu = self.mu_out(fx)\n",
    "        sd = torch.nn.functional.softplus(self.sigma_out(fx)) + 1e-5\n",
    "        return a, mu, sd\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_conv(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.avgpool(x).reshape(len(x),-1)\n",
    "\n",
    "        a,mu,sd = self.get_vars(x)\n",
    "        return a, mu, sd\n",
    "\n",
    "    def setup_distr(self,x):\n",
    "        a, mu, sd = self(x)\n",
    "        return self.get_distr(a,mu,sd)\n",
    "    \n",
    "    def get_distr(self, w, center, spread):\n",
    "        mix = dist.Categorical(w)\n",
    "        comp = dist.Normal(center, spread)\n",
    "        return dist.MixtureSameFamily(mix, comp)\n",
    "\n",
    "class res_bmm(res_gmm):\n",
    "    def get_vars(self, fx):\n",
    "        c = self.a_out(fx).softmax(dim=1)\n",
    "        alpha = self.mu_out(fx).exp()\n",
    "        beta = self.sigma_out(fx).exp()\n",
    "        return c, alpha, beta\n",
    "    \n",
    "    def setup_distr(self, x):\n",
    "        comp_weights, alpha, beta = self(x)\n",
    "        return self.get_distr(comp_weights, alpha, beta)\n",
    "    \n",
    "    def get_distr(self, w, center, spread):\n",
    "        mix = dist.Categorical(w)\n",
    "        comp = dist.Beta(center, spread)\n",
    "        return dist.MixtureSameFamily(mix, comp)\n",
    "    \n",
    "kwargs = {\n",
    "    \"num_comp\": 10,\n",
    "    \"drop_p\": 0.5,\n",
    "    \"layer_counts\": [2,2,2],\n",
    "    \"chans\": [12,24,48],\n",
    "    \"bnorm\": True,\n",
    "    \"lnorm\": False,\n",
    "    \"leading_norm\": True,\n",
    "    \"noise\": 0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_feature_rep(exp_trial, world_num=None, world_rep=None, cutoff=None, resize_shape=None):\n",
    "\n",
    "    if exp_trial:\n",
    "        world_rep = utils.load_trial(world_num, experiment=\"prediction\", hole=1)\n",
    "    else:\n",
    "        assert not (world_rep is None)\n",
    "        \n",
    "    world_rep_unity = visual.unity_transform_trial(world_rep)\n",
    "    n_holes = len(world_rep_unity[\"hole_positions\"])\n",
    "    imgs = []\n",
    "    for hole in range(n_holes):\n",
    "        img = get_img(world_rep_unity, hole, cutoff=cutoff, resize_shape=resize_shape)\n",
    "        imgs.append(img)\n",
    "    return imgs\n",
    "\n",
    "def create_data_arrays(df_data, beta_scale=False, cutoff=cutoff, resize_shape=resize_shape):\n",
    "\n",
    "    feature_reps_dict = {}\n",
    "\n",
    "    for world_num in df_data[\"world\"].unique():\n",
    "        world_dict = {}\n",
    "        tr_rep = create_feature_rep(True, world_num=world_num, cutoff=cutoff, resize_shape=resize_shape)\n",
    "        for hole in [1,2,3]:\n",
    "            world_dict[hole] = tr_rep[hole-1]\n",
    "        feature_reps_dict[world_num] = world_dict\n",
    "\n",
    "    input_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for ind, row in df_data.iterrows():\n",
    "        world_num = int(row[\"world\"])\n",
    "        hole = int(row[\"hole\"])\n",
    "        response = row[\"response\"]\n",
    "\n",
    "        if beta_scale:\n",
    "            og_shape = 600\n",
    "            response /= og_shape\n",
    "        \n",
    "        tr_rep = feature_reps_dict[world_num][hole]\n",
    "\n",
    "        input_list.append(tr_rep)\n",
    "        label_list.append(response)\n",
    "\n",
    "    input_np = np.array(input_list)\n",
    "    label_np = np.array(label_list)\n",
    "\n",
    "    return input_np, label_np\n",
    "\n",
    "class MLPDataSet(utils_data.Dataset):\n",
    "\n",
    "    def __init__(self, inputs, labels):\n",
    "\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inpt = self.inputs[idx]\n",
    "        label = self.labels[idx]\n",
    "        return inpt, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_data = human_data[human_data[\"world\"].isin(train_worlds)]\n",
    "# df_valid_data = human_data[human_data[\"world\"].isin(valid_worlds)]\n",
    "\n",
    "def process_human_data(train_data, valid_data, beta_scale=True, cutoff=32, resize_shape=(100,120)):\n",
    "    train_inputs_np, train_labels_np = create_data_arrays(train_data, beta_scale=beta_scale, cutoff=cutoff, resize_shape=resize_shape)\n",
    "    valid_inputs_np, valid_labels_np = create_data_arrays(valid_data, beta_scale=beta_scale, cutoff=cutoff, resize_shape=resize_shape)\n",
    "    return train_inputs_np, train_labels_np, valid_inputs_np, valid_labels_np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model and Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model_type, model_kwargs, lrs,\n",
    "               train_data, valid_data, process_data,\n",
    "               resize_shape=resize_shape, cutoff=cutoff,\n",
    "               batch_size=50, beta_scale=True,\n",
    "               print_prog=False, n_epochs=100,\n",
    "               init_model_path=None, combos=None,\n",
    "               data_tup=None,\n",
    "              ):\n",
    "    if data_tup is None:\n",
    "        print(\"Preprocessing the Image Data\")\n",
    "        data_tup = process_data(train_data, valid_data, beta_scale=beta_scale, resize_shape=resize_shape, cutoff=cutoff)\n",
    "    train_input_np, train_label_np, valid_input_np, valid_label_np = data_tup\n",
    "    \n",
    "    train_input_torch = torch.FloatTensor(train_input_np)\n",
    "    train_label_torch = torch.FloatTensor(train_label_np)\n",
    "    print(\"Input Shape:\", train_input_torch.shape)\n",
    "    print(\"Label Shape:\", train_label_torch.shape)\n",
    "    \n",
    "    valid_input_torch = torch.FloatTensor(valid_input_np)\n",
    "    valid_label_torch = torch.FloatTensor(valid_label_np)\n",
    "    \n",
    "    train_ds = MLPDataSet(train_input_torch, train_label_torch)\n",
    "    train_dl = utils_data.DataLoader(train_ds,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "    model_kwargs[\"input_shape\"] = train_input_torch.shape\n",
    "    return_results = False\n",
    "    results = []\n",
    "    if combos is None:\n",
    "        combos = [model_kwargs]\n",
    "    else:\n",
    "        print(\"Searching Over:\", list(combos[0].keys()))\n",
    "        combos = [{**model_kwargs, **combo} for combo in combos]\n",
    "    for lr in lrs:\n",
    "        for combo in combos:\n",
    "            try:\n",
    "                print()\n",
    "                print(\"New Training - LR:\", lr)\n",
    "                print(\"Model Kwargs:\")\n",
    "                for k,v in combo.items():\n",
    "                    print(\"\\t\", k,v)\n",
    "                model = model_type(**combo)\n",
    "                if init_model_path:\n",
    "                    checkpt = torch.load(init_model_path)\n",
    "                    model.load_state_dict(checkpt[\"state_dict\"])\n",
    "                optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                            lr = lr,\n",
    "                                            weight_decay=0.01)\n",
    "                model.to(device)\n",
    "                \n",
    "                train_loss_record = []\n",
    "                valid_loss_record = []\n",
    "                bpe = len(train_dl)\n",
    "                train_n = len(train_ds)\n",
    "                best_loss = np.inf\n",
    "                \n",
    "                for epoch in range(n_epochs):\n",
    "                    data_iter = iter(train_dl)\n",
    "                \n",
    "                    model.train()\n",
    "                \n",
    "                    train_epoch_loss = 0\n",
    "                \n",
    "                    for i,(batch_inp, batch_lab) in enumerate(data_iter):\n",
    "                        optimizer.zero_grad()\n",
    "                        distr = model.setup_distr(batch_inp.to(device))\n",
    "                        loss = -distr.log_prob(batch_lab.to(device)).sum()\n",
    "                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                        train_epoch_loss += loss.item()\n",
    "                        if print_prog:\n",
    "                            print(round(100*(i/len(data_iter))), \"%\", end=\"          \\r\")\n",
    "                \n",
    "                    \n",
    "                    train_loss_record.append(train_epoch_loss/train_n)\n",
    "                \n",
    "                    model.eval()\n",
    "                \n",
    "                    with torch.no_grad():\n",
    "                        vbsize = 1000\n",
    "                        valid_loss = 0\n",
    "                        for j in range(0,len(valid_input_torch),vbsize):\n",
    "                            inpts =  valid_input_torch[j:j+batch_size]\n",
    "                            labels = valid_label_torch[j:j+batch_size]\n",
    "                            valid_distr = model.setup_distr(inpts.to(device))\n",
    "                            valid_loss += -valid_distr.log_prob(labels.to(device)).sum().item()\n",
    "                        valid_loss = valid_loss/valid_input_torch.shape[0]\n",
    "                        valid_loss_record.append(valid_loss)\n",
    "                    if valid_loss<best_loss:\n",
    "                        best_loss = valid_loss\n",
    "                        best_model_sd = model.state_dict()\n",
    "                        best_epoch = epoch\n",
    "                \n",
    "                    print(\"Epoch\", epoch, \"-- Loss\", train_epoch_loss/train_n, \"-- Val:\", valid_loss)\n",
    "                    \n",
    "            except KeyboardInterrupt as e:\n",
    "                return_results = True\n",
    "            model.cpu()\n",
    "            results.append({\n",
    "                \"lr\": lr,\n",
    "                \"model\": model,\n",
    "                \"train_loss\": train_loss_record,\n",
    "                \"val_loss\": valid_loss_record,\n",
    "                \"model_kwargs\": model_kwargs,\n",
    "                \"best_model_sd\": best_model_sd,\n",
    "                \"best_loss\": best_loss,\n",
    "                \"best_epoch\": best_epoch,\n",
    "            })\n",
    "            del optimizer\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            if return_results:\n",
    "                return results, data_tup\n",
    "    return results, data_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combos(d, combo=None, keys=None, idx=0, combos=None):\n",
    "    \"\"\"\n",
    "    This function will return a list of combination dicts.\n",
    "    \n",
    "    Args:\n",
    "        d: dict\n",
    "            the dict with the keys to be searched over and\n",
    "            values that are lists of the values to be searched\n",
    "            over.\n",
    "    Ignorable Args:\n",
    "        combo: dict\n",
    "            the current combo\n",
    "        keys: list\n",
    "            the keys that are being searched over\n",
    "        idx: int\n",
    "            the current recursion level\n",
    "        combos: list of dicts\n",
    "            the resulting list of parameter dicts\n",
    "    Returns:\n",
    "        list of dicts\n",
    "    \"\"\"\n",
    "    if combo is None: combo = dict()\n",
    "    if keys is None:\n",
    "        keys = list(d.keys())\n",
    "    if combos is None:\n",
    "        combos = []\n",
    "    if idx>=len(keys):\n",
    "        combos.append(combo)\n",
    "        return combos\n",
    "    k = keys[idx]\n",
    "    for v in d[k]:\n",
    "        get_combos(d, combo={k:v, **combo}, keys=keys, idx=idx+1, combos=combos)\n",
    "    return combos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can find human data at /data/human_data/prediction/prediction_long.csv\n",
    "# cv_splits: has world indices which can be converted into world numbers which is a column in prediction long\n",
    "# create a train and eval set filtered on the world numbers in the cv_splits data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class res_bmm(res_gmm):\n",
    "    def get_vars(self, fx):\n",
    "        c = self.a_out(fx).softmax(dim=1)\n",
    "        alpha = self.mu_out(fx).exp()\n",
    "        beta = self.sigma_out(fx).exp()\n",
    "        return c, alpha, beta\n",
    "    \n",
    "    def setup_distr(self, x):\n",
    "        comp_weights, alpha, beta = self(x)\n",
    "        return self.get_distr(comp_weights, alpha, beta)\n",
    "    \n",
    "    def get_distr(self, w, center, spread):\n",
    "        mix = dist.Categorical(w)\n",
    "        comp = dist.Beta(center, spread)\n",
    "        return dist.MixtureSameFamily(mix, comp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMM Simulated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved_sims/train_phys_worlds.pkl\", \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "with open(\"saved_sims/val_phys_worlds.pkl\", \"rb\") as f:\n",
    "    val_data = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Data Size:\", len(train_data))\n",
    "print(\"Valid Data Size:\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_phys_data(train_data, val_data, beta_scale=True, cutoff=32, resize_shape=(100,120), verbose=True):\n",
    "    train_X, train_y = process_visual_data(train_data, beta_scale=beta_scale, cutoff=cutoff, resize_shape=resize_shape, verbose=verbose)\n",
    "    val_X, val_y = process_visual_data(val_data, beta_scale=beta_scale, cutoff=cutoff, resize_shape=resize_shape, verbose=verbose)\n",
    "    return train_X, train_y, val_X, val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model, Data -- Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [5e-4,]\n",
    "model_type = res_bmm\n",
    "batch_size = 50\n",
    "n_epochs = 20\n",
    "beta_scale = True\n",
    "kwargs = {\n",
    "    \"num_comp\": 10,\n",
    "    \"noise\": 0.08,\n",
    "    \"layer_counts\": [2,2,2],\n",
    "    \"chans\": [12,24,48],\n",
    "    \"bnorm\": True,\n",
    "    \"lnorm\": False,\n",
    "    \"leading_norm\": True,\n",
    "}\n",
    "overrides = {\n",
    "    \"noise\": [0.08] #, 0.11],\n",
    "}\n",
    "combos = get_combos(overrides)\n",
    "\n",
    "results, data_tup = train_loop(\n",
    "    model_type, kwargs, lrs,\n",
    "    train_data=train_data,\n",
    "    valid_data=val_data,\n",
    "    process_data=process_phys_data,\n",
    "    batch_size=batch_size,\n",
    "    beta_scale=beta_scale,\n",
    "    print_prog=True,\n",
    "    n_epochs=n_epochs,\n",
    "    combos=combos,\n",
    ")\n",
    "\n",
    "(train_inputs_np, train_labels_np, valid_inputs_np, valid_labels_np) = data_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = None\n",
    "min_loss = np.inf\n",
    "model = None\n",
    "for i,res in enumerate(results): \n",
    "    lr = res[\"lr\"]\n",
    "    train_loss_record = res[\"train_loss\"]\n",
    "    valid_loss_record = res[\"val_loss\"]\n",
    "    plt.plot(range(len(train_loss_record)), train_loss_record, label=\"train_loss\")\n",
    "    plt.plot(range(len(valid_loss_record)), valid_loss_record, color=\"red\", label=\"validation_loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.ylim([np.min(train_loss_record)-1,max(np.max(valid_loss_record), np.max(train_loss_record))])\n",
    "    plt.title(f\"LR: {lr}\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    #plt.savefig(\"plots/mlp_bmm_loss_curve.jpg\",\n",
    "    #            dpi=200,\n",
    "    #            bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    loss = np.min(valid_loss_record[-1])\n",
    "    if loss<min_loss:\n",
    "        best_idx = i\n",
    "        best_lr = lr\n",
    "        min_loss = loss\n",
    "        model = res[\"model\"]\n",
    "        best_res = res\n",
    "        \n",
    "best_model_data = {\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"lr\": best_res[\"lr\"],\n",
    "    \"train_loss\": best_res[\"train_loss\"],\n",
    "    \"val_loss\": best_res[\"val_loss\"],\n",
    "    \"model_kwargs\": best_res[\"model_kwargs\"],\n",
    "}\n",
    "torch.save(best_model_data, \"nn_checkpoints/best_phys_cnn_bmm.pth\")\n",
    "\n",
    "print(\"Best LR:\", best_lr, \"-- Train Loss:\", results[best_idx][\"train_loss\"][-1], \"-- Val Loss:\", results[best_idx][\"val_loss\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_worlds = world_num_splits[\"train\"]\n",
    "valid_worlds = world_num_splits[\"test\"]\n",
    "test_worlds = world_num_splits[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs = [5e-4]\n",
    "model_type = res_bmm\n",
    "batch_size = 50\n",
    "beta_scale = True\n",
    "n_epochs = 30\n",
    "kwargs = {\n",
    "    \"num_comp\": 10,\n",
    "    \"drop_p\": 0.5,\n",
    "    \"layer_counts\": [2,2,2],\n",
    "    \"chans\": [12,24,48],\n",
    "    \"bnorm\": True,\n",
    "    \"lnorm\": False,\n",
    "    \"leading_norm\": True,\n",
    "    \"noise\": 0.01,\n",
    "}\n",
    "\n",
    "init_model_path = \"nn_checkpoints/best_phys_cnn_bmm.pth\"\n",
    "\n",
    "opt_epochs = []\n",
    "opt_model_sds = []\n",
    "end_model_sds = []\n",
    "models = []\n",
    "\n",
    "split = 0\n",
    "for train_split, valid_split in zip(train_worlds, valid_worlds):\n",
    "\n",
    "    print(\"Split:\", split)\n",
    "    print()\n",
    "\n",
    "    df_train_data = human_data[human_data[\"world\"].isin(train_split)]\n",
    "    df_valid_data = human_data[human_data[\"world\"].isin(valid_split)]\n",
    "        \n",
    "    results, data_tup = train_loop(\n",
    "        model_type, kwargs, lrs,\n",
    "        train_data=df_train_data,\n",
    "        valid_data=df_valid_data,\n",
    "        process_data=process_human_data,\n",
    "        batch_size=batch_size,\n",
    "        beta_scale=beta_scale,\n",
    "        init_model_path=init_model_path,\n",
    "        n_epochs=n_epochs,\n",
    "    )\n",
    "    (train_input_np, train_label_np, valid_input_np, valid_label_np) = data_tup\n",
    "    train_loss_record = results[0][\"train_loss\"]\n",
    "    valid_loss_record = results[0][\"val_loss\"]\n",
    "\n",
    "    models.append(results[0][\"model\"].cpu())\n",
    "    end_model_sds.append(results[0][\"model\"].state_dict())\n",
    "\n",
    "    min_epoch = min(list(enumerate(valid_loss_record)), key=lambda x: x[1])[0]\n",
    "\n",
    "    opt_model_sds.append(results[0][\"best_model_sd\"])\n",
    "    opt_epochs.append(min_epoch)\n",
    "\n",
    "    split += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    for k,v in res[\"best_model_sd\"].items():\n",
    "        res[\"best_model_sd\"][k] = v.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_means = []\n",
    "mlp_kde_dict = {}\n",
    "\n",
    "x_values = torch.linspace(0.0001,0.9999,600).unsqueeze(1)\n",
    "\n",
    "results = []\n",
    "for mi,(test_split, model, model_sd) in enumerate(zip(test_worlds, models, opt_model_sds)):\n",
    "    print(f\"Testing {mi}/{len(test_worlds)}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    model.load_state_dict(model_sd)\n",
    "    model.eval()\n",
    "    \n",
    "    # Setup input for given split\n",
    "    test_input_list = []\n",
    "    for world_num in test_split:\n",
    "        test_input_list += create_feature_rep(True, world_num, resize_shape=resize_shape, cutoff=cutoff)\n",
    "    test_input_np = np.array(test_input_list)\n",
    "\n",
    "    test_input_torch = torch.from_numpy(test_input_np).float()\n",
    "\n",
    "    # Get predictions and setup bmm\n",
    "    tcw_list = []\n",
    "    ta_list = []\n",
    "    tb_list = []\n",
    "    bsize = 100\n",
    "    for i in range(0,len(test_input_torch), bsize):\n",
    "        test_comp_weights, test_alpha, test_beta = model(test_input_torch[i:i+bsize])\n",
    "        tcw_list.append(test_comp_weights.cpu())\n",
    "        ta_list.append(test_alpha.cpu())\n",
    "        tb_list.append(test_beta.cpu())\n",
    "    model.cpu()\n",
    "    test_comp_weights = torch.cat(tcw_list, dim=0)\n",
    "    test_alpha = torch.cat(ta_list, dim=0)\n",
    "    test_beta = torch.cat(tb_list, dim=0)\n",
    "    test_bmm = model.get_distr(test_comp_weights, test_alpha, test_beta)\n",
    "\n",
    "    # Get means\n",
    "    test_bmm_means = test_bmm.mean.detach().cpu().numpy() * 600\n",
    "\n",
    "    # Get pdf\n",
    "    log_probs = test_bmm.log_prob(x_values)\n",
    "    pdf = torch.exp(log_probs)/600\n",
    "    pdf_np = pdf.cpu().detach().numpy().T\n",
    "\n",
    "    mlp_means += list(zip(np.repeat(test_split, 3), test_bmm_means))\n",
    "    split_kde = kep.make_kde_dict(pdf_np, test_split)\n",
    "\n",
    "    mlp_kde_dict.update(split_kde)\n",
    "    \n",
    "    res_dict = {\n",
    "        \"test_bmm_means\": test_bmm_means,\n",
    "        \"log_probs\": log_probs.cpu().detach().numpy(),\n",
    "        \"pdf\": pdf_np,\n",
    "        \"kde_dicts\": split_kde,\n",
    "    }\n",
    "    results.append(res_dict)\n",
    "\n",
    "d = \"saved_model_pred/\"\n",
    "if not os.path.exists(d):\n",
    "    os.mkdir(d)\n",
    "f = os.path.join(d,\"cnn_w_pretraining_cvsplits.p\")\n",
    "with open(f, \"wb\") as f:\n",
    "    pickle.dump(results, f)\n",
    "print(\"Saved to\", f)\n",
    "\n",
    "mlp_means.sort(key=lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [5e-4]\n",
    "model_type = res_bmm\n",
    "batch_size = 50\n",
    "beta_scale = True\n",
    "n_epochs = 30\n",
    "kwargs = {\n",
    "    \"num_comp\": 10,\n",
    "    \"drop_p\": 0.5,\n",
    "    \"layer_counts\": [2,2,2],\n",
    "    \"chans\": [12,24,48],\n",
    "    \"bnorm\": True,\n",
    "    \"lnorm\": False,\n",
    "    \"leading_norm\": True,\n",
    "    \"noise\": 0.01,\n",
    "}\n",
    "\n",
    "init_model_path = \"nn_checkpoints/best_phys_cnn_bmm.pth\"\n",
    "\n",
    "opt_epochs = []\n",
    "opt_model_sds = []\n",
    "end_model_sds = []\n",
    "models = []\n",
    "\n",
    "split = 0\n",
    "data_split = list(train_worlds[0]) + list(valid_worlds[0])#+ list(test_worlds[0])\n",
    "df_train_data = human_data[human_data[\"world\"].isin(data_split)]\n",
    "df_valid_data = human_data[human_data[\"world\"].isin(valid_worlds[0])]\n",
    "\n",
    "    \n",
    "results, data_tup = train_loop(\n",
    "    model_type, kwargs, lrs,\n",
    "    train_data=df_train_data,\n",
    "    valid_data=df_valid_data,\n",
    "    process_data=process_human_data,\n",
    "    batch_size=batch_size,\n",
    "    beta_scale=beta_scale,\n",
    "    init_model_path=init_model_path,\n",
    "    n_epochs=n_epochs,\n",
    ")\n",
    "(train_input_np, train_label_np, valid_input_np, valid_label_np) = data_tup\n",
    "train_loss_record = results[0][\"train_loss\"]\n",
    "valid_loss_record = results[0][\"val_loss\"]\n",
    "\n",
    "models.append(results[0][\"model\"].cpu())\n",
    "end_model_sds.append(results[0][\"model\"].state_dict())\n",
    "\n",
    "min_epoch = min(list(enumerate(valid_loss_record)), key=lambda x: x[1])[0]\n",
    "\n",
    "opt_model_sds.append(results[0][\"best_model_sd\"])\n",
    "opt_epochs.append(min_epoch)\n",
    "\n",
    "split += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_means = []\n",
    "mlp_kde_dict = {}\n",
    "\n",
    "x_values = torch.linspace(0.0001,0.9999,600).unsqueeze(1)\n",
    "\n",
    "results = []\n",
    "mi = 0\n",
    "test_split = sorted(data_split)\n",
    "model = models[0]\n",
    "model_sd = opt_model_sds[0]\n",
    "\n",
    "print(f\"Testing\")\n",
    "torch.cuda.empty_cache()\n",
    "model.load_state_dict(model_sd)\n",
    "model.eval()\n",
    "\n",
    "# Setup input for given split\n",
    "test_input_list = []\n",
    "for world_num in test_split:\n",
    "    test_input_list += create_feature_rep(True, world_num, resize_shape=resize_shape, cutoff=cutoff)\n",
    "test_input_np = np.array(test_input_list)\n",
    "\n",
    "test_input_torch = torch.from_numpy(test_input_np).float()\n",
    "\n",
    "# Get predictions and setup bmm\n",
    "tcw_list = []\n",
    "ta_list = []\n",
    "tb_list = []\n",
    "bsize = 100\n",
    "for i in range(0,len(test_input_torch), bsize):\n",
    "    test_comp_weights, test_alpha, test_beta = model(test_input_torch[i:i+bsize])\n",
    "    tcw_list.append(test_comp_weights.cpu())\n",
    "    ta_list.append(test_alpha.cpu())\n",
    "    tb_list.append(test_beta.cpu())\n",
    "model.cpu()\n",
    "test_comp_weights = torch.cat(tcw_list, dim=0)\n",
    "test_alpha = torch.cat(ta_list, dim=0)\n",
    "test_beta = torch.cat(tb_list, dim=0)\n",
    "test_bmm = model.get_distr(test_comp_weights, test_alpha, test_beta)\n",
    "\n",
    "# Get means\n",
    "test_bmm_means = test_bmm.mean.detach().cpu().numpy() * 600\n",
    "\n",
    "# Get pdf\n",
    "log_probs = test_bmm.log_prob(x_values)\n",
    "pdf = torch.exp(log_probs)/600\n",
    "pdf_np = pdf.cpu().detach().numpy().T\n",
    "\n",
    "mlp_means += list(zip(np.repeat(test_split, 3), test_bmm_means))\n",
    "split_kde = kep.make_kde_dict(pdf_np, test_split)\n",
    "\n",
    "mlp_kde_dict.update(split_kde)\n",
    "\n",
    "res_dict = {\n",
    "    \"test_bmm_means\": test_bmm_means,\n",
    "    \"log_probs\": log_probs.cpu().detach().numpy(),\n",
    "    \"pdf\": pdf_np,\n",
    "    \"kde_dicts\": split_kde,\n",
    "}\n",
    "results.append(res_dict)\n",
    "\n",
    "f = \"saved_model_pred/cnn_w_pretraining_alldata.p\"\n",
    "with open(f, \"wb\") as f:\n",
    "    pickle.dump(results, f)\n",
    "print(\"Saved to\", f)\n",
    "\n",
    "mlp_means.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, mlp_mean_vals = zip(*mlp_means)\n",
    "\n",
    "r = np.round(np.corrcoef(human_means[\"mean\"], mlp_mean_vals)[0,1], decimals=2)\n",
    "rmse = np.round(root_mean_squared_error(human_means[\"mean\"], mlp_mean_vals), decimals=2)\n",
    "\n",
    "print(\"r:\", r)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_dict = {\n",
    "    \"human\": human_means[\"mean\"].to_numpy(),\n",
    "    \"mlp\": mlp_mean_vals,\n",
    "    \"hole\": [1,2,3]*40\n",
    "}\n",
    "\n",
    "df_to_show = pd.DataFrame(means_dict)\n",
    "\n",
    "# plt.scatter(human_means[\"mean\"], mlp_mean_vals)\n",
    "plt.plot([0,600], [0,600], color=\"black\", zorder=1)\n",
    "sns.scatterplot(data=df_to_show,\n",
    "                x=\"mlp\", \n",
    "                y=\"human\", \n",
    "                hue=\"hole\", \n",
    "                palette=[rgb_green, rgb_skyblue, rgb_magenta])\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"Badass CNN Mean Prediction\", fontsize=20)\n",
    "plt.ylabel(\"Human Mean Response\", fontsize=20)\n",
    "\n",
    "plt.xlim(0,600)\n",
    "plt.ylim(0,600)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# remove the legend\n",
    "plt.legend([],[], frameon=False)\n",
    "\n",
    "plt.text(10, 570, f\"r = {r}\", fontsize=14)\n",
    "plt.text(9, 535, f\"RMSE = {rmse}\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp_emd = kep.compute_emds(mlp_kde_dict, human_kde_dict, worlds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean:\", round(df_mlp_emd[\"EMD\"].mean(), 2))\n",
    "print()\n",
    "print(\"Quantiles:\")\n",
    "print(df_mlp_emd[\"EMD\"].quantile([0.05, 0.95]).round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_mlp_emd, x=\"EMD\")\n",
    "\n",
    "plt.xlabel(\"CNN EMD\", fontsize=20)\n",
    "plt.ylabel(\"Count\", fontsize=20)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# remove the legend\n",
    "plt.legend([],[], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_kde_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_num = worlds[0]\n",
    "print(world_num)\n",
    "kep.plot_kdes(mlp_kde_dict, world_num, colors=[rgb_green, rgb_skyblue, rgb_magenta], alpha=0.8, format=\"wide\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plinko",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
